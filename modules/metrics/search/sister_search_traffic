#!/bin/bash

hive -S --hiveconf mapred.job.queue.name=nice -e "USE wmf;
ADD JAR hdfs:///wmf/refinery/current/artifacts/refinery-hive.jar;
CREATE TEMPORARY FUNCTION normalize_host AS 'org.wikimedia.analytics.refinery.hive.GetHostPropertiesUDF';
WITH sister_search_pvs AS (
  SELECT
    '$1' AS date, access_method,
    CASE normalized_host.project
         WHEN 'commons' THEN 'wikimedia commons'
         WHEN 'simple' THEN CONCAT('simple ', normalized_host.project_class)
         WHEN 'species' THEN 'wikispecies'
         ELSE normalized_host.project_class
    END AS project,
    CASE WHEN normalized_host.project IN('commons', 'meta', 'simple', 'incubator', 'species') THEN ''
         WHEN normalized_host.project = 'en' THEN 'English'
         -- frwiki and cawiki use homebrew sister search that shows up in addition to ours
         WHEN normalized_host.project IN('ca', 'fr') THEN 'French and Catalan'
         ELSE 'Other languages'
    END AS language,
    -- flag for pageviews that are search results pages (e.g. if user clicked to see more results from a sister project):
    (
      page_id IS NULL
      AND (
        uri_path = '/wiki/Special:Search'
        OR (
          uri_path = '/w/index.php'
          AND (
            PARSE_URL(CONCAT('http://', uri_host, uri_path, uri_query), 'QUERY', 'search') IS NOT NULL
            OR PARSE_URL(CONCAT('http://', uri_host, uri_path, uri_query), 'QUERY', 'searchToken') IS NOT NULL
          )
        )
      )
    ) AS is_serp
  FROM webrequest
  WHERE
    webrequest_source = 'text'
    AND CONCAT(year, '-', LPAD(month, 2, '0'), '-', LPAD(day, 2, '0')) >= '$1'
    AND CONCAT(year, '-', LPAD(month, 2, '0'), '-', LPAD(day, 2, '0')) < '$2'
    AND is_pageview
    -- only those that have been referred by a search results page on a wikipedia:
    AND referer_class = 'internal'
    AND (
      PARSE_URL(referer, 'QUERY', 'search') IS NOT NULL
      OR PARSE_URL(referer, 'QUERY', 'searchToken') IS NOT NULL
    )
    -- warning: comparing uri_host = PARSE_URL(referer, 'HOST') would mark 'en.m.wikipedia.org' as a sister of 'en.wikipedia.org'
    AND normalize_host(PARSE_URL(referer, 'HOST')).project_class = 'wikipedia'
    AND normalize_host(PARSE_URL(referer, 'HOST')).project_class != normalized_host.project_class
    AND NOT normalized_host.project_class IN('mediawiki', 'wikimediafoundation', 'wikidata')
    AND NOT normalized_host.project IN('meta', 'incubator')
    -- keep commons.wikimedia.org and species.wikimedia.org:
    AND NOT (normalized_host.project_class = 'wikimedia' AND NOT (normalized_host.project IN('commons', 'species')))
)
SELECT date, access_method, project, language, IF(is_serp, 'TRUE', 'FALSE') AS is_serp, COUNT(1) AS pageviews
FROM sister_search_pvs
GROUP BY date, access_method, project, language, IF(is_serp, 'TRUE', 'FALSE')
ORDER BY date, access_method, project, language, is_serp
LIMIT 10000;
" 2> /dev/null | grep -v parquet.hadoop | grep -v WARN:
