#!/bin/bash

hive -S --hiveconf mapred.job.queue.name=nice -e "ADD JAR hdfs:///wmf/refinery/current/artifacts/refinery-hive.jar;
CREATE TEMPORARY FUNCTION is_external_search AS 'org.wikimedia.analytics.refinery.hive.IsExternalSearchUDF';
CREATE TEMPORARY FUNCTION get_engine AS 'org.wikimedia.analytics.refinery.hive.IdentifySearchEngineUDF';
USE wmf;
SELECT
  '$1' AS \`date\`,
  IF(is_external_search(referer), 'TRUE', 'FALSE') AS is_search,
  referer_class,
  get_engine(referer) as search_engine,
  access_method,
  COUNT(*) AS pageviews
FROM webrequest
WHERE
  webrequest_source = 'text'
  AND CONCAT(year, '-', LPAD(month, 2, '0'), '-', LPAD(day, 2, '0')) >= '$1'
  AND CONCAT(year, '-', LPAD(month, 2, '0'), '-', LPAD(day, 2, '0')) < '$2'
  AND is_pageview
  AND access_method IN('desktop', 'mobile web')
  AND get_engine(referer) != 'unknown'
  AND referer_class != 'unknown'
  AND NOT (referer_class = 'external (search engine)' AND get_engine(referer) = 'none')
  AND agent_type = 'user'
GROUP BY
  '$1',
  IF(is_external_search(referer), 'TRUE', 'FALSE'),
  referer_class,
  get_engine(referer),
  access_method;
" 2> /dev/null | grep -v parquet.hadoop | grep -v WARN:
