#!/bin/bash

hive -S --hiveconf mapred.job.queue.name=nice -e "ADD JAR hdfs:///wmf/refinery/current/artifacts/refinery-hive.jar;
CREATE TEMPORARY FUNCTION is_external_search AS 'org.wikimedia.analytics.refinery.hive.IsExternalSearchUDF';
CREATE TEMPORARY FUNCTION get_engine AS 'org.wikimedia.analytics.refinery.hive.IdentifySearchEngineUDF';
USE wmf;
SELECT
  '$1' AS date,
  IF(is_external_search(referer), 'TRUE', 'FALSE') AS is_search,
  referer_class,
  get_engine(referer) as search_engine,
  COUNT(1) AS pageviews
FROM webrequest
WHERE
  webrequest_source = 'text'
  AND CONCAT(year, '-', LPAD(month, 2, '0'), '-', LPAD(day, 2, '0')) >= '$1'
  AND CONCAT(year, '-', LPAD(month, 2, '0'), '-', LPAD(day, 2, '0')) < '$2'
  AND content_type RLIKE('^text/html')
  AND uri_host RLIKE('^(www\\.)?wikipedia.org/*$')
  AND (
    INSTR(uri_path, 'search-redirect.php') = 0
    OR NOT referer RLIKE('^(https?://www\\.)?wikipedia.org/+search-redirect.php')
  )
  AND NOT referer RLIKE('^http://localhost')
  AND agent_type = 'user'
  AND get_engine(referer) != 'unknown'
  AND referer_class != 'unknown'
  AND NOT (referer_class = 'external (search engine)' AND get_engine(referer) = 'none')
  AND http_status IN('200', '304')
GROUP BY
  '$1',
  IF(is_external_search(referer), 'TRUE', 'FALSE'),
  referer_class,
  get_engine(referer);
" 2> /dev/null | grep -v parquet.hadoop | grep -v WARN:
